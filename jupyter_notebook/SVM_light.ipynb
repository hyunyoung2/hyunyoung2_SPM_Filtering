{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, The file(/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_HAMVector ) read\n",
      "len of test_ham_svm: 5000\n",
      "Currently, The file(/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_SPMVector ) read\n",
      "len of test_spm_svm: 5000\n",
      "len of test_svm: 10000\n",
      "-1\t1:1.5917160000000001\t2:-0.06001600000000007\t3:-2.317329\t4:-3.8193589999999995\t5:0.907905\t6:-3.124571\t7:-0.07144900000000007\t8:-1.061829\t9:-0.6851829999999999\t10:-0.2752840000000001\t11:3.6963269999999997\t12:3.8794690000000003\t13:-1.8299360000000002\t14:-1.9473989999999999\t15:2.441315\t16:-1.8231129999999998\t17:2.657318\t18:0.17293099999999995\t19:-0.454046\t20:-2.4547760000000003\t21:-3.7171960000000004\t22:1.469587\t23:-0.559072\t24:-2.613014\t25:-1.2385190000000001\t26:1.0808170000000001\t27:-0.097218\t28:3.9861940000000002\t29:-0.8689779999999999\t30:-0.372558\t31:3.126285\t32:1.7829549999999998\t33:-1.7818260000000001\t34:2.3201549999999997\t35:4.450599\t36:2.4950829999999997\t37:2.069417\t38:-3.3635780000000004\t39:5.979712\t40:-2.816815\t41:2.140257\t42:2.62393\t43:1.233367\t44:-4.610815\t45:1.6831840000000002\t46:-1.104909\t47:-2.1262109999999996\t48:-4.878132\t49:-0.742332\t50:2.8066120000000003\t51:0.7286840000000001\t52:-1.236575\t53:-2.245295\t54:-0.836341\t55:3.5972020000000002\t56:4.217224\t57:-0.572891\t58:3.334403\t59:-1.1514350000000002\t60:-3.319388\t61:0.044983000000000106\t62:1.137282\t63:-1.150169\t64:-4.26685\t65:-0.32051699999999994\t66:-1.2515749999999999\t67:-2.64692\t68:-2.472747\t69:3.16717\t70:1.3005829999999998\t71:3.55795\t72:0.7314139999999999\t73:0.503956\t74:-1.279718\t75:-2.711479\t76:4.074868\t77:-1.6888840000000003\t78:1.134089\t79:-0.836112\t80:-0.7370080000000001\t81:2.7620749999999994\t82:1.63695\t83:-0.686858\t84:-0.852704\t85:2.4038210000000007\t86:0.26862400000000003\t87:-0.08262\t88:-2.4011250000000004\t89:6.87074\t90:-1.2250050000000001\t91:-1.6066289999999996\t92:-3.161666\t93:1.7815210000000001\t94:-3.8695290000000004\t95:-1.019086\t96:1.044586\t97:-1.4171870000000002\t98:1.476916\t99:-2.833203\t100:2.9394349999999996\t101:-0.15408299999999997\t102:0.21454599999999996\t103:0.5569729999999999\t104:-1.94041\t105:1.743803\t106:3.669681\t107:2.032847\t108:2.712816\t109:0.817951\t110:0.582347\t111:3.9520180000000003\t112:2.254427\t113:-1.2020450000000003\t114:2.124364\t115:-0.340514\t116:0.810825\t117:-1.332419\t118:2.2123329999999997\t119:-0.24888000000000007\t120:1.1918840000000002\t121:-1.407854\t122:0.7838900000000001\t123:0.6065240000000001\t124:-4.738989999999999\t125:-0.351633\t126:-0.966453\t127:0.283317\t128:-2.7531760000000003\t129:0.5224449999999999\t130:0.70065\t131:1.2633649999999998\t132:1.9830449999999997\t133:-0.020175000000000026\t134:0.47761899999999985\t135:0.49811700000000003\t136:0.123233\t137:-0.28145199999999987\t138:0.33480100000000007\t139:2.700192\t140:-1.5190129999999997\t141:-3.485281\t142:-0.17393100000000006\t143:-1.356445\t144:-2.6759329999999997\t145:0.8660949999999998\t146:3.3060660000000004\t147:1.8132079999999997\t148:-2.854006\t149:-3.5562399999999994\t150:-3.237826\t151:-0.9263880000000001\t152:0.012192000000000022\t153:-2.259414\t154:1.4949450000000002\t155:-2.0264759999999997\t156:-1.4649290000000001\t157:0.917927\t158:-0.11925699999999997\t159:-0.34292\t160:-1.6291630000000001\t161:1.044001\t162:0.271764\t163:0.789108\t164:4.700395\t165:2.054987\t166:0.46006599999999975\t167:-2.6012839999999997\t168:0.1547880000000001\t169:3.4042499999999998\t170:-0.5913889999999999\t171:-0.2976599999999999\t172:0.5656909999999999\t173:-1.865697\t174:-5.842403\t175:0.22144999999999995\t176:-0.20156299999999996\t177:-0.38868800000000003\t178:0.15564500000000003\t179:-2.0107329999999997\t180:-2.6565519999999996\t181:-3.689991\t182:0.91869\t183:2.5790569999999997\t184:0.90504\t185:-3.508758\t186:1.9721319999999998\t187:3.02889\t188:4.049223\t189:1.967451\t190:1.085774\t191:-2.2545420000000003\t192:-0.25836099999999995\t193:-1.4281350000000002\t194:1.250419\t195:-0.9064840000000001\t196:2.309569\t197:-3.384532\t198:-1.4464860000000002\t199:-2.620791\t200:-2.731502\t201:-1.16948\t202:-0.723032\t203:4.431657\t204:-0.4803219999999999\t205:-0.734092\t206:-2.5441000000000003\t207:0.11558799999999994\t208:1.0969\t209:-0.11288299999999996\t210:2.9402940000000006\t211:-2.984075\t212:1.967837\t213:-2.822746\t214:2.603009\t215:0.5048469999999999\t216:0.267832\t217:2.307115\t218:3.3617540000000004\t219:0.250398\t220:3.3279069999999997\t221:-0.215238\t222:-0.295764\t223:1.6386420000000002\t224:0.6098250000000001\t225:0.35485699999999987\t226:-1.744905\t227:-5.380738999999999\t228:-0.159083\t229:2.256458\t230:2.617788\t231:-0.9062459999999999\t232:0.7083389999999999\t233:-3.224872\t234:-0.8450970000000001\t235:0.4853590000000001\t236:0.688848\t237:0.78464\t238:2.008396\t239:-3.913775\t240:-0.497317\t241:1.6821229999999998\t242:1.9216529999999998\t243:-2.4503219999999994\t244:1.445122\t245:0.08863400000000002\t246:-0.6565859999999999\t247:3.131321\t248:-1.723291\t249:-1.727679\t250:-2.862031000000001\t251:0.921177\t252:-0.06545199999999997\t253:-0.840114\t254:2.1805559999999997\t255:2.054493\t256:2.595397\t257:1.8465430000000003\t258:-0.890997\t259:-3.789364\t260:1.295145\t261:0.07447500000000003\t262:-0.9584879999999998\t263:2.7994149999999998\t264:-2.594988\t265:-0.909686\t266:5.14756\t267:2.948901\t268:-0.369092\t269:1.758749\t270:0.6773309999999999\t271:-0.04224799999999999\t272:2.1525510000000003\t273:0.19496299999999994\t274:0.8820479999999999\t275:-0.641354\t276:1.840653\t277:-4.354908\t278:2.091716\t279:-1.8023219999999998\t280:1.7263950000000001\t281:-1.2123339999999998\t282:-0.38056499999999993\t283:0.8080639999999999\t284:-0.852919\t285:-1.092936\t286:3.6196569999999997\t287:-2.6168070000000005\t288:-1.099449\t289:1.7620049999999998\t290:-0.4789399999999999\t291:0.590073\t292:-0.692944\t293:3.4263220000000003\t294:2.167635\t295:0.396969\t296:0.4644809999999999\t297:1.627424\t298:-1.3740640000000002\t299:0.22540600000000008\t300:0.38327900000000004\t\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Currently, The file(/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_HAMvector ) read\n",
      "len of train_ham_svm: 49993\n",
      "Currently, The file(/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_SPMVector ) read\n",
      "len of train_spm_svm: 50000\n",
      "len of train_svm: 99993\n",
      "-1\t1:-0.357646\t2:0.705737\t3:-0.108669\t4:-1.1114579999999998\t5:-0.586364\t6:0.09705599999999998\t7:1.075788\t8:-0.485612\t9:-0.458445\t10:0.04034499999999991\t11:0.210839\t12:-1.1038770000000002\t13:0.56436\t14:-0.339371\t15:-0.08621299999999993\t16:0.554719\t17:-1.251699\t18:-0.433043\t19:-0.300006\t20:-0.003176000000000012\t21:0.04841100000000001\t22:-0.03956500000000002\t23:-1.26199\t24:-0.20325999999999997\t25:-0.638898\t26:0.04566899999999999\t27:-0.45433199999999996\t28:0.39874\t29:-0.849347\t30:-0.7596700000000001\t31:-0.17609\t32:-0.23605299999999999\t33:0.036855\t34:0.32693400000000006\t35:0.09078299999999999\t36:0.267951\t37:0.763434\t38:-0.761117\t39:0.739795\t40:-0.43885799999999997\t41:-0.088955\t42:-0.11479400000000001\t43:0.202145\t44:-1.712999\t45:0.258512\t46:-0.11572999999999997\t47:0.517908\t48:-0.435532\t49:-0.621111\t50:0.16665099999999997\t51:0.071241\t52:0.117343\t53:0.08233499999999999\t54:0.43594099999999997\t55:0.6704030000000001\t56:0.8314429999999999\t57:-0.782527\t58:-0.19874000000000003\t59:-0.504498\t60:-0.480856\t61:0.9421520000000001\t62:0.5252829999999999\t63:-1.115353\t64:-0.42069999999999996\t65:0.164957\t66:-0.02576600000000001\t67:0.564262\t68:0.30279300000000003\t69:1.736641\t70:0.18759299999999998\t71:0.319433\t72:-0.82205\t73:-0.12220400000000001\t74:-0.42245200000000005\t75:-0.707486\t76:-0.6596120000000001\t77:-0.33423499999999995\t78:-0.729012\t79:-1.241648\t80:-0.087516\t81:0.35989399999999994\t82:1.947253\t83:0.476712\t84:-0.6565949999999999\t85:0.608988\t86:1.090419\t87:-0.676701\t88:-0.4637860000000001\t89:0.565563\t90:-0.09578400000000004\t91:-0.304634\t92:-0.41733400000000004\t93:0.660569\t94:-0.318902\t95:-0.813145\t96:0.05477399999999999\t97:0.28118699999999996\t98:-1.7804399999999998\t99:0.444894\t100:-0.226427\t101:0.252778\t102:0.679516\t103:0.825201\t104:0.120446\t105:0.40261100000000005\t106:0.8644390000000001\t107:-0.06332900000000002\t108:-0.7155119999999999\t109:-0.520038\t110:0.07658900000000002\t111:0.10848400000000002\t112:0.707778\t113:-1.4650370000000001\t114:0.5795640000000001\t115:-0.020635999999999988\t116:-1.298764\t117:-0.497123\t118:-0.398764\t119:-1.304703\t120:-0.972708\t121:0.386945\t122:-0.389568\t123:1.037417\t124:-0.469573\t125:0.09727\t126:0.21439799999999998\t127:-0.35914899999999994\t128:-0.151356\t129:0.35343600000000003\t130:0.806742\t131:0.9084840000000001\t132:0.650892\t133:-0.33681700000000003\t134:0.437157\t135:0.750544\t136:-0.246645\t137:0.526339\t138:-0.928568\t139:0.6591999999999999\t140:0.07540199999999997\t141:-0.591422\t142:-0.224753\t143:0.288327\t144:0.025386999999999993\t145:0.314301\t146:0.09761299999999998\t147:0.43037499999999995\t148:-1.056058\t149:-1.316393\t150:0.17705700000000002\t151:0.8785970000000001\t152:0.594514\t153:-1.227973\t154:-0.830048\t155:0.263493\t156:0.35303599999999996\t157:-0.24975399999999992\t158:-0.15783599999999998\t159:-0.158633\t160:-1.9319230000000003\t161:-0.115125\t162:-0.33952\t163:-0.037418999999999994\t164:0.06619800000000003\t165:0.863077\t166:-0.432917\t167:-0.046483000000000003\t168:1.056051\t169:0.963843\t170:0.111348\t171:-0.825473\t172:0.574062\t173:-0.410369\t174:-0.8761410000000001\t175:-0.16822199999999998\t176:0.44338399999999994\t177:-0.724832\t178:-0.453598\t179:-0.423164\t180:-0.16609900000000002\t181:-0.506634\t182:-0.369768\t183:0.430558\t184:0.037755\t185:-2.5988689999999997\t186:-0.106265\t187:0.205054\t188:0.447832\t189:0.533468\t190:0.591164\t191:0.1292399999999999\t192:-0.296953\t193:-0.5170279999999999\t194:0.068407\t195:0.894564\t196:1.9595090000000002\t197:-1.362049\t198:0.55809\t199:-0.63527\t200:-0.19676300000000002\t201:-0.54598\t202:-0.838665\t203:0.41547999999999996\t204:0.04986099999999999\t205:0.319742\t206:0.5642199999999999\t207:-0.7065170000000001\t208:-0.5200279999999999\t209:0.474305\t210:0.029885000000000023\t211:-0.24221399999999998\t212:0.738077\t213:-0.524781\t214:-0.49882699999999996\t215:0.361254\t216:0.32901\t217:0.362673\t218:0.720866\t219:-0.575778\t220:1.116129\t221:-0.111938\t222:0.061882999999999994\t223:0.327984\t224:-0.09730800000000003\t225:-1.4846219999999999\t226:0.202074\t227:-1.287183\t228:1.1611960000000001\t229:0.751425\t230:0.21324799999999997\t231:0.5411600000000001\t232:-0.185724\t233:-0.079866\t234:0.254184\t235:0.24400199999999997\t236:0.36762300000000003\t237:-0.44508099999999995\t238:1.091787\t239:-1.107357\t240:-1.048733\t241:0.928103\t242:0.44618\t243:-0.5660959999999999\t244:0.272854\t245:-1.715814\t246:-0.089698\t247:0.18926400000000004\t248:0.33842399999999995\t249:-0.734549\t250:-0.30942400000000003\t251:0.12418300000000002\t252:0.30745\t253:-0.5488839999999999\t254:0.635211\t255:0.800246\t256:0.337139\t257:0.064993\t258:0.051278000000000046\t259:-0.28653399999999996\t260:0.486226\t261:1.186895\t262:-0.778659\t263:0.41456799999999994\t264:-0.9818160000000001\t265:-0.09848499999999999\t266:0.11064699999999997\t267:0.02574399999999999\t268:0.145392\t269:-0.760416\t270:0.240767\t271:-0.143007\t272:0.489124\t273:0.985417\t274:0.22347499999999998\t275:-0.267774\t276:2.101733\t277:-0.701201\t278:0.639939\t279:0.8318460000000001\t280:0.22340899999999997\t281:-0.277443\t282:0.12506499999999998\t283:0.428786\t284:0.08991\t285:-0.480541\t286:0.198713\t287:-0.9883299999999999\t288:0.553032\t289:1.5773669999999997\t290:-0.12670499999999996\t291:-0.6479550000000001\t292:-0.201788\t293:-0.155008\t294:-0.501008\t295:-1.249918\t296:-0.974671\t297:-0.34621399999999997\t298:0.05227900000000002\t299:-0.588869\t300:0.750196\t\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "99993\n"
     ]
    }
   ],
   "source": [
    "#LightNVM \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def changeFormatOfDataForSVMLight(a_list, spm) :\n",
    "\n",
    "    for idx1, var1 in enumerate(a_list) :\n",
    "        temp_str = str()\n",
    "        temp = var1.split()\n",
    "        for idx2, var2 in enumerate(temp) :\n",
    "            temp_var = float(var2)\n",
    "            if spm == True : \n",
    "                if idx2 == 0 :\n",
    "                    temp_str += (\"-1\\t\"+str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "                elif idx2 == (len(a_list)-1) :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var))\n",
    "                else :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "            else :\n",
    "                if idx2 == 0 :\n",
    "                    temp_str += (\"+1\\t\"+str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "                elif idx2 == (len(a_list)-1) :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var))\n",
    "                else :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "        a_list[idx1] = temp_str\n",
    "    return a_list\n",
    "    \n",
    "\n",
    "def WriteArrayForSVM_light(file_handler, a_list) :\n",
    "    for idx, var in enumerate(a_list) :\n",
    "            if idx <= 10 :\n",
    "                print (idx)\n",
    "            file_handler.write(var+\"\\n\")\n",
    "            \n",
    "# @ function : Read a file without blank line\n",
    "# For example : \n",
    "# [\"Hellow world\\n\", \"\\n\", \"Hi\\n\"] --> [\"Hellow world\\n\", \"Hi\\n\"]\n",
    "# input : file path \n",
    "# output : a set of Lists of Words\n",
    "def readAFileLineByLine (file_path) :\n",
    "    f = open(file_path, \"r\")\n",
    "    # due to iconv not dealing with conversion between EUC-KR and UTF-8\n",
    "    a_whole_list = [x for x in f.readlines() if x != \"\\n\"]\n",
    "    f.close()\n",
    "    # For Debugging\n",
    "    print (\"Currently, The file(\" + file_path, \") read\")    \n",
    "    return a_whole_list\n",
    "\n",
    "\n",
    "CBOW_testSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/CBOW_HAMVector\",\n",
    "             \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/CBOW_SPMVector\"]\n",
    "CBOW_trainSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/CBOW_HAMvector\",\n",
    "              \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/CBOW_SPMVector\"]\n",
    "\n",
    "SKIP_GRAM_testSen2Vec =[\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_HAMVector\",\n",
    "             \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_SPMVector\"]\n",
    "SKIP_GRAM_trainSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_HAMvector\",\n",
    "              \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_SPMVector\"]\n",
    "\n",
    "\n",
    "# To store it in the \n",
    "CBOW_SVM_Lihgt_test = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/test/CBOW_SVM_Light_test\"\n",
    "\n",
    "CBOW_SVM_Lihgt_train = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/train/CBOW_SVM_Light_train\"\n",
    "                              \n",
    "SKIP_GRAM_SVM_Lihgt_test = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/test/SKIP_GRAM_SVM_Light_test\"\n",
    "\n",
    "SKIP_GRAM_SVM_Lihgt_train = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/train/SKIP_GRAM_SVM_Light_train\"\n",
    "                     \n",
    "\n",
    "def main(test_ham, test_spm, train_ham, train_spm, target_train, target_test) :\n",
    "    path1 = test_ham\n",
    "    path2 = test_spm\n",
    "    path3 = train_ham\n",
    "    path4 = train_spm\n",
    "    \n",
    "    #for SVM Light \n",
    "    svm_light_train=target_train\n",
    "    svm_light_test=target_test\n",
    "   \n",
    "    # for Test\n",
    "    test_ham_list=readAFileLineByLine(path1)\n",
    "    test_ham_svm = changeFormatOfDataForSVMLight(test_ham_list, False)\n",
    "    \n",
    "    print (\"len of test_ham_svm:\", len(test_ham_svm))\n",
    "    \n",
    "    test_spm_list=readAFileLineByLine(path2)\n",
    "    test_spm_svm = changeFormatOfDataForSVMLight(test_spm_list, True)\n",
    "    \n",
    "    print (\"len of test_spm_svm:\", len(test_spm_svm))\n",
    "    \n",
    "    test_svm = test_ham_svm + test_spm_svm \n",
    "    print (\"len of test_svm:\", len(test_svm))\n",
    "    print (test_svm[-1])\n",
    "    with open(svm_light_test, \"w\") as svm_light_test_writer : \n",
    "            WriteArrayForSVM_light(svm_light_test_writer, test_svm)\n",
    "    \n",
    "    # for train\n",
    "    train_ham_list=readAFileLineByLine(path3)\n",
    "    train_ham_svm = changeFormatOfDataForSVMLight(train_ham_list, False)\n",
    "    \n",
    "    print (\"len of train_ham_svm:\", len(train_ham_svm))\n",
    "    \n",
    "    train_spm_list=readAFileLineByLine(path4)\n",
    "    train_spm_svm = changeFormatOfDataForSVMLight(train_spm_list, True)\n",
    "    \n",
    "    print (\"len of train_spm_svm:\", len(train_spm_svm))  \n",
    "\n",
    "    train_svm = train_ham_svm + train_spm_svm\n",
    "    print (\"len of train_svm:\", len(train_svm)) \n",
    "    print (train_svm[-1])\n",
    "    with open(svm_light_train, \"w\") as svm_light_train_writer : \n",
    "            WriteArrayForSVM_light(svm_light_train_writer, train_svm)\n",
    "    \n",
    "    print (len(test_svm))\n",
    "    print (len(train_svm))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\" :\n",
    "    #main(CBOW_testSen2Vec[0], CBOW_testSen2Vec[1], CBOW_trainSen2Vec[0], CBOW_trainSen2Vec[1], CBOW_SVM_Lihgt_train, CBOW_SVM_Lihgt_test)\n",
    "    main(SKIP_GRAM_testSen2Vec[0], SKIP_GRAM_testSen2Vec[1], SKIP_GRAM_trainSen2Vec[0], SKIP_GRAM_trainSen2Vec[1], SKIP_GRAM_SVM_Lihgt_train, SKIP_GRAM_SVM_Lihgt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author : Hyunyoung2 \n",
    "\n",
    "# To represent the format fit to SVM_Light enginea\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# To read vector file \n",
    "# for vector \n",
    "CBOW_testSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/CBOW_HAMVector\",\n",
    "             \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/CBOW_SPMVector\"]\n",
    "CBOW_trainSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/CBOW_HAMvector\",\n",
    "              \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/CBOW_SPMVector\"]\n",
    "\n",
    "SKIP_GRAM_testSen2Vec =[\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_HAMVector\",\n",
    "             \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_SPMVector\"]\n",
    "SKIP_GRAM_trainSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_HAMvector\",\n",
    "              \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_SPMVector\"]\n",
    "\n",
    "\n",
    "# To store it in the \n",
    "CBOW_SVM_Lihgt_test = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/test/CBOW_SVM_Light_test\"\n",
    "\n",
    "CBOW_SVM_Lihgt_train = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/train/CBOW_SVM_Light_train\"\n",
    "                              \n",
    "SKIP_GRAM_SVM_Lihgt_test = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/test/SKIP_GRAM_SVM_Light_test\"\n",
    "\n",
    "SKIP_GRAM_SVM_Lihgt_train = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/train/SKIP_GRAM_SVM_Light_train\"\n",
    "                     \n",
    "# Read the file of vectors, a line is a factor in list\n",
    "def readVector(file):\n",
    "    \n",
    "    with open(file, \"r\") as rf:\n",
    "        lineByLine = [ tuple(x.split(\"\\t\")) for x in rf.readlines() if x != \"\\n\" ]\n",
    "        \n",
    "    print(file, \":\", len(lineByLine))\n",
    "    \n",
    "    return lineByLine\n",
    "\n",
    "\n",
    "# change the form fit to SVM Light engine\n",
    "def SVMLightFormat(vector, spm):\n",
    "    \n",
    "    for vectorIdx, vectorVal in enumerate(vector):\n",
    "        temp_factor = str()\n",
    "        for factorIdx, factorVal in enumerate(vectorVal):\n",
    "            floatFactorVal = float(factorVal)\n",
    "            if spm == True:\n",
    "                if factorIdx == 0:\n",
    "                    temp_factor += (\"-1\"+\"\\t\"+str(factorIdx+1)+\":\"+str(floatFactorVal)+\"\\t\")\n",
    "                elif factorIdx == (len(vector)-1):\n",
    "                    temp_factor += (str(factorIdx+1)+\":\"+str(floatFactorVal))\n",
    "                else:\n",
    "                    temp_factor += (str(factorIdx+1)+\":\"+str(floatFactorVal)+\"\\t\")\n",
    "            elif spm == False:\n",
    "                if factorIdx == 0:\n",
    "                    temp_factor += (\"+1\"+\"\\t\"+str(factorIdx+1)+\":\"+str(floatFactorVal)+\"\\t\")\n",
    "                elif factorIdx == (len(vector)-1):\n",
    "                    temp_factor += (str(factorIdx+1)+\":\"+str(floatFactorVal))\n",
    "                else:\n",
    "                    temp_factor += (str(factorIdx+1)+\":\"+str(floatFactorVal)+\"\\t\")\n",
    "        vector[vectorIdx] = temp_factor\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def writeVectorSVMLight(vector, fileHandler):\n",
    "    for vectorIdx, vectorVal in enumerate(vector):\n",
    "        fileHandler.write(vectorVal+\"\\n\")\n",
    "        \n",
    "            \n",
    "def main():\n",
    "    # fixed dimensionality \n",
    "    dim = 300\n",
    "    \n",
    "    # CBOW \n",
    "    ## Test\n",
    "    with open(CBOW_SVM_Lihgt_test, \"w\") as wf:\n",
    "        for CBOWTestIdx, CBOWTestVal in enumerate(CBOW_testSen2Vec):\n",
    "            print(\"reading\", CBOWTestVal, \"......\")\n",
    "            vector = readVector(CBOWTestVal)\n",
    "            print(\"writing\", CBOW_SVM_Lihgt_test, \".......\\n\")\n",
    "            if CBOWTestIdx == 0:  # 0 means HAM(false)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, False), wf)\n",
    "            else:  # 1 means SPM(true)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, True), wf)\n",
    "    ## train\n",
    "    with open(CBOW_SVM_Lihgt_train, \"w\") as wf:\n",
    "        for CBOWTrainIdx, CBOWTrainVal in enumerate(CBOW_trainSen2Vec):\n",
    "            print(\"reading\", CBOWTrainVal, \"......\")\n",
    "            vector = readVector(CBOWTrainVal)\n",
    "            print(\"writing\", CBOW_SVM_Lihgt_train, \".......\\n\")\n",
    "            if CBOWTrainIdx == 0:  # 0 means HAM(false)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, False), wf)\n",
    "            else:  # 1 means SPM(true)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, True), wf)\n",
    "    # SKIP_GRAM \n",
    "    ## test\n",
    "    with open(SKIP_GRAM_SVM_Lihgt_test, \"w\") as wf:\n",
    "        for SKIP_GRAM_testIdx, SKIP_GRAM_testVal in enumerate(SKIP_GRAM_testSen2Vec):\n",
    "            print(\"reading\", SKIP_GRAM_testVal, \"......\")\n",
    "            vector = readVector(SKIP_GRAM_testVal)\n",
    "            print(\"writing\", SKIP_GRAM_SVM_Lihgt_test, \".......\\n\")\n",
    "            if SKIP_GRAM_testIdx == 0:  # 0 means HAM(false)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, False), wf)\n",
    "            else:  # 1 means SPM(true)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, True), wf)\n",
    "    \n",
    "    ## train\n",
    "    with open(SKIP_GRAM_SVM_Lihgt_train, \"w\") as wf:\n",
    "        for SKIP_GRAM_TrainIdx, SKIP_GRAM_TrainVal in enumerate(SKIP_GRAM_trainSen2Vec):\n",
    "            print(\"reading\", SKIP_GRAM_TrainVal, \"......\")\n",
    "            vector = readVector(SKIP_GRAM_TrainVal)\n",
    "            print(\"writing\", SKIP_GRAM_SVM_Lihgt_train, \".......\\n\")\n",
    "            if SKIP_GRAM_TrainIdx == 0:  # 0 means HAM(false)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, False), wf)\n",
    "            else:  # 1 means SPM(true)\n",
    "                writeVectorSVMLight(SVMLightFormat(vector, True), wf)\n",
    "                \n",
    "    print(\"changing is done!!\")\n",
    "    \n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.94330330e-10   1.00000000e+00]\n",
      " [  6.43885076e-01   3.56114894e-01]]\n",
      "[[  4.10708237  26.46854401]\n",
      " [  3.17772675   2.58545995]] \n",
      " [[  1.94330330e-10   1.00000000e+00]\n",
      " [  6.43885076e-01   3.56114894e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer on `w`.\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "    # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "\n",
    "    # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "    # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "    # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    y_val, output_val = sess.run([y, output])\n",
    "    print(y_val,\"\\n\", output_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.constant([20])\n",
    "y = tf.add(w, x)\n",
    "output = tf.nn.softmax(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer on `w`.\n",
    "\n",
    "    # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "    # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "\n",
    "    # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "    # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "    # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    y_val, output_val = sess.run([y, output])\n",
    "    print(y_val,\"\\n\", output_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   5.40436935e-27]\n",
      " [  7.46464655e-02   9.25353527e-01]\n",
      " [  3.73457432e-01   6.26542568e-01]]\n",
      "[[ 0.94487703  0.46228993]]\n",
      "[[ 37.94487762 -22.53771019]\n",
      " [  1.94487703   4.46228981]\n",
      " [  2.94487715   3.46228981]] \n",
      " [[  1.00000000e+00   5.40436935e-27]\n",
      " [  7.46464655e-02   9.25353527e-01]\n",
      " [  3.73457432e-01   6.26542568e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0], [2.0, 3.0]])\n",
    "w = tf.get_variable(\"Layer2_bias_output\", [1,2], dtype=tf.float32)\n",
    "y = tf.add(w, x)\n",
    "output = tf.nn.softmax(y)\n",
    "\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer on `w`.\n",
    "    sess.run(init_OP)\n",
    "\n",
    "    # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "    # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "\n",
    "    # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "    # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "    # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    w_val, y_val, output_val = sess.run([w, y, output])\n",
    "    print(w_val)\n",
    "    print\n",
    "    print(y_val,\"\\n\", output_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 2 and 3 for 'Add' (op: 'Add') with input shapes: [2,1], [3,2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 2 and 3 for 'Add' (op: 'Add') with input shapes: [2,1], [3,2].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a239f8c8582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m37.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m23.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Layer2_bias_output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 183\u001b[0;31m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 2 and 3 for 'Add' (op: 'Add') with input shapes: [2,1], [3,2]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0], [2.0, 3.0]])\n",
    "w = tf.get_variable(\"Layer2_bias_output\", [2,1], dtype=tf.float32)\n",
    "y = tf.add(w, x)\n",
    "output = tf.nn.softmax(y)\n",
    "\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer on `w`.\n",
    "    sess.run(init_OP)\n",
    "\n",
    "    # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "    # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "\n",
    "    # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "    # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "    # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    w_val, y_val, output_val = sess.run([w, y, output])\n",
    "    print(w_val)\n",
    "    print\n",
    "    print(y_val,\"\\n\", output_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightNVM \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def changeFormatOfDataForSVMLight(a_list, spm) :\n",
    "\n",
    "    for idx1, var1 in enumerate(a_list) :\n",
    "        temp_str = str()\n",
    "        temp = var1.split()\n",
    "        for idx2, var2 in enumerate(temp) :\n",
    "            temp_var = float(var2)\n",
    "            if spm == True : \n",
    "                if idx2 == 0 :\n",
    "                    temp_str += (\"-1\\t\"+str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "                elif idx2 == (len(a_list)-1) :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var))\n",
    "                else :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "            else :\n",
    "                if idx2 == 0 :\n",
    "                    temp_str += (\"1\\t\"+str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "                elif idx2 == (len(a_list)-1) :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var))\n",
    "                else :\n",
    "                    temp_str += (str(idx2+1)+\":\"+str(temp_var)+\"\\t\")\n",
    "        a_list[idx1] = temp_str\n",
    "    return a_list\n",
    "    \n",
    "\n",
    "def WriteArrayForSVM_light(file_handler, a_list) :\n",
    "    for idx, var in enumerate(a_list) :\n",
    "            if idx <= 10 :\n",
    "                print (idx)\n",
    "            file_handler.write(var+\"\\n\")\n",
    "            \n",
    "# @ function : Read a file without blank line\n",
    "# For example : \n",
    "# [\"Hellow world\\n\", \"\\n\", \"Hi\\n\"] --> [\"Hellow world\\n\", \"Hi\\n\"]\n",
    "# input : file path \n",
    "# output : a set of Lists of Words\n",
    "def readAFileLineByLine (file_path) :\n",
    "    f = open(file_path, \"r\")\n",
    "    # due to iconv not dealing with conversion between EUC-KR and UTF-8\n",
    "    a_whole_list = [x for x in f.readlines() if x != \"\\n\"]\n",
    "    f.close()\n",
    "    # For Debugging\n",
    "    print (\"Currently, The file(\" + file_path, \") read\")    \n",
    "    return a_whole_list\n",
    "\n",
    "\n",
    "CBOW_testSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/CBOW_HAMVector\",\n",
    "             \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/CBOW_SPMVector\"]\n",
    "CBOW_trainSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/CBOW_HAMvector\",\n",
    "              \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/CBOW_SPMVector\"]\n",
    "\n",
    "SKIP_GRAM_testSen2Vec =[\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_HAMVector\",\n",
    "             \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/test/SKIP_GRAM_SPMVector\"]\n",
    "SKIP_GRAM_trainSen2Vec = [\"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_HAMvector\",\n",
    "              \"/home/hyunyoung2/My_lab/smart_conference/data/Vector/train/SKIP_GRAM_SPMVector\"]\n",
    "\n",
    "\n",
    "# To store it in the \n",
    "CBOW_SVM_Lihgt_test = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/test/CBOW_SVM_Light_test\"\n",
    "\n",
    "CBOW_SVM_Lihgt_train = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/train/CBOW_SVM_Light_train\"\n",
    "                              \n",
    "SKIP_GRAM_SVM_Lihgt_test = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/test/SKIP_GRAM_SVM_Light_test\"\n",
    "\n",
    "SKIP_GRAM_SVM_Lihgt_train = \"/home/hyunyoung2/My_lab/smart_conference/data/SVM_Light/train/SKIP_GRAM_SVM_Light_train\"\n",
    "                     \n",
    "\n",
    "def CBOWmain(test_ham, test_spm, train_ham, train_spm, target_train, target_test) :\n",
    "    path1 = test_ham\n",
    "    path2 = test_spm\n",
    "    path3 = train_ham\n",
    "    path4 = train_spm\n",
    "    \n",
    "    #for SVM Light \n",
    "    svm_light_train=target_train\n",
    "    svm_light_test=target_test\n",
    "   \n",
    "    # for Test\n",
    "    test_ham_list=readAFileLineByLine(path1)\n",
    "    test_ham_svm = changeFormatOfDataForSVMLight(test_ham_list, False)\n",
    "    \n",
    "    print (len(test_ham_svm))\n",
    "    \n",
    "    test_spm_list=readAFileLineByLine(path2)\n",
    "    test_spm_svm = changeFormatOfDataForSVMLight(test_spm_list, True)\n",
    "    \n",
    "    print (len(test_spm_svm))\n",
    "    test_svm = test_ham_svm + test_spm_svm \n",
    "    print (test_svm[-1])\n",
    "    with open(svm_light_test, \"w\") as svm_light_test_writer : \n",
    "            WriteArrayForSVM_light(svm_light_test_writer, test_svm)\n",
    "    \n",
    "    # for train\n",
    "    train_ham_list=readAFileLineByLine(path3)\n",
    "    train_ham_svm = changeFormatOfDataForSVMLight(train_ham_list, False)\n",
    "    print (train_ham_svm[-1])\n",
    "    print (len(train_ham_svm))\n",
    "    \n",
    "    train_spm_list=readAFileLineByLine(path4)\n",
    "    train_spm_svm = changeFormatOfDataForSVMLight(train_spm_list, True)\n",
    "    \n",
    "    print (len(train_spm_svm))\n",
    "    train_svm = train_ham_svm + train_spm_svm\n",
    "    print (train_svm[-1])\n",
    "    with open(svm_light_train, \"w\") as svm_light_train_writer : \n",
    "            WriteArrayForSVM_light(svm_light_train_writer, train_svm)\n",
    "    \n",
    "    print (len(test_svm))\n",
    "    print (len(train_svm))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\" :\n",
    "    main(CBOW_testSen2Vec[0], CBOW_testSen2Vec[1], CBOW_trainSen2Vec[0], CBOW_trainSen2Vec[1], CBOW_SVM_Lihgt_train, CBOW_SVM_Lihgt_test)\n",
    "    main(SKIP_GRAM_testSen2Vec[0], SKIP_GRAM_testSen2Vec[1], SKIP_GRAM_trainSen2Vec[0], SKIP_GRAM_trainSen2Vec[1], SKIP_GRAM_SVM_Lihgt_train, SKIP_GRAM_SVM_Lihgt_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
